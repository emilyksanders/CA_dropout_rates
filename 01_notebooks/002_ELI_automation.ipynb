{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6c459-b596-401f-96e0-37768820e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec37fe-4e9b-43f2-bc9d-7b4ae3886f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to grab \n",
    "#### maybe put something here that would break up each subject so that we can run the loop through it\n",
    "### ask emily what the urls are in. like how would i call them to be read\n",
    "def fetch_and_filter(urls, existing_df=None):\n",
    "    # Read the URL's from the URL list with the specified delimiter and encoding\n",
    "    for url in urls:\n",
    "        # Read the data from the URL with the specified delimiter and encoding \n",
    "        try:\n",
    "            df = pd.read_csv(url, delimiter='\\t', encoding= 'ISO-8859-1')\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {url}: {e}\")\n",
    "            return None\n",
    "        \n",
    "        #### Potentialy add different dilemtites here or encodings but ask emily\n",
    "        \n",
    "        #####get emilys code for change column\n",
    "        \n",
    "        # Define the filter criteria\n",
    "        filter_criteria = {\n",
    "            'AggregateLevel': 'd',\n",
    "            'CharterSchool': 'all',\n",
    "            'DASS': 'all',\n",
    "            'SchoolGradeSpan': 'all',\n",
    "            'SubjectArea': 'ta'\n",
    "        } ####Fix the names of the columns and ask emily for common ones\n",
    "        \n",
    "        # Apply filters to the DataFrame\n",
    "        for col, val in filter_criteria.items():\n",
    "            if col in df.columns:\n",
    "                df = df[df[col].str.lower() == val]\n",
    "        \n",
    "        # List of columns to drop, if they exist\n",
    "        columns_to_drop = ['AggregateLevel', 'SchoolCode', 'SchoolName', 'ReportingCategory', 'CharterYN']\n",
    "        for col in columns_to_drop:\n",
    "            if col in df.columns:\n",
    "                df.drop(columns=[col], inplace=True)\n",
    "        ### Ask emily if we want to just do this after? maybe only put common ones?\n",
    "        \n",
    "        # Concatenate with the existing DataFrame if provided\n",
    "        if existing_df is not None:\n",
    "            existing_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        else:\n",
    "            existing_df = df\n",
    "            \n",
    "        ### put in something here about merging if it has a similar url but the numbers are different\n",
    "        ### or maybe it would just be too separate loops. one for the subject. one for the url in the subject\n",
    "    \n",
    "        # save as a combined csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45d650-ca47-4baa-9a67-15b3dc244cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fetch_and_filter(urls, existing_df=None, delimiters, encodings):\n",
    "    \n",
    "    for url in urls:\n",
    "        # Read the data from the URL with the specified delimiter and encoding\n",
    "        try:\n",
    "            df = pd.read_csv(url, delimiter=delimiters, encoding=encodings)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read data for {url}: {e}\")\n",
    "            continue  # Skip to the next URL if there's an error\n",
    "\n",
    "        # Standardize column names (e.g., replace spaces or underscores with consistent format)\n",
    "        df.columns = df.columns.str.replace(' ', '').str.replace('_', '')\n",
    "\n",
    "        # Define the filter criteria\n",
    "        filter_criteria = {\n",
    "            'AggregateLevel': 'd',\n",
    "            'CharterSchool': 'all',\n",
    "            'DASS': 'all',\n",
    "            'SchoolGradeSpan': 'all',\n",
    "            'SubjectArea': 'ta'\n",
    "        }\n",
    "        \n",
    "        # Apply filters to the DataFrame\n",
    "        for col, val in filter_criteria.items():\n",
    "            if col in df.columns:\n",
    "                df = df[df[col].str.lower() == val]\n",
    "\n",
    "        # List of columns to drop, if they exist\n",
    "        columns_to_drop = ['AggregateLevel', 'SchoolCode', 'SchoolName', 'ReportingCategory', 'CharterYN']\n",
    "        for col in columns_to_drop:\n",
    "            if col in df.columns:\n",
    "                df.drop(columns=[col], inplace=True)\n",
    "\n",
    "        # Concatenate with the existing DataFrame if provided\n",
    "        if existing_df is not None:\n",
    "            existing_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        else:\n",
    "            existing_df = df\n",
    "\n",
    "    # Save the final combined DataFrame as a CSV (optional step)\n",
    "    # existing_df.to_csv('combined_output.csv', index=False)\n",
    "    \n",
    "    return existing_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
